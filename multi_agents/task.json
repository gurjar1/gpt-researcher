{
  "query": "What are the best practices for running AI models locally with Ollama?",
  "max_sections": 2,
  "publish_formats": {
    "markdown": true,
    "pdf": false,
    "docx": false
  },
  "include_human_feedback": false,
  "follow_guidelines": false,
  "model": "llama3.1",
  "guidelines": [
    "The report MUST be written in APA format",
    "Each sub section MUST include supporting sources using hyperlinks"
  ],
  "verbose": true
}